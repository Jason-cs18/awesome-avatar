## SadTalker: Learning Realistic 3D Motion Coefficients for Stylized Audio-Driven Single Image Talking Face Animation
A VAE-based posenet is integrated with a new talking-face generation pipeline SadTalker to generate diverse head motions on talking-face videos.

![SadTalker overview](https://github.com/Jason-cs18/awesome-avatar/blob/main/assets/sadtalker.png "SadTalker overview")

**What's new:** Wenxuan Zhang from xi'an jiaotong university and researchers from Tencent AI Lab proposed a new generation pipeline named SadTalker to synthesis diverse and stylized talking-face videos.

**Key insights:** Previous works leverages xxx to achieve xxx but they are limited by xxx. To overcome xxx, authors designed xxx.

**How it works:** The authors designed three-stage pipeline named xxx to generate xxx. In the first, xxx-1. In the second, xxx-2. In the end, xxx-3.    
- xxx-1 is trained with xxx. Compared with existing works, xxx is better than xxx. It is because that xxx.
- xxx-2 is trained with xxx. Compared with existing works, xxx is better than xxx. It is because that xxx.
- xxx-3 is trained with xxx. Compared with existing works, xxx is better than xxx. It is because that xxx.

**Results:** The authors evaluated xxx on xxx. Compared with xxx, xxx is better on xxx. But it is worse than xxx on xxx. It is because that xxx.

**Why it matters:** This work reveals that xxx but xxx. Such insights deepen our understanding of xxx and can help practitioners explain their outputs.

**We're thinking:** xxx-1 and xxx-2 may be useful for other pipelines because xxx.

